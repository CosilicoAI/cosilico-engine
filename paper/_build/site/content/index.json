{"version":3,"kind":"Article","sha256":"16ccf22c5dce8e5d1bf640e83d47ae89e0203c57a4303591d64f6205147d7e6d","slug":"index","location":"/index.md","dependencies":[],"frontmatter":{"title":"AI-Driven Rules-as-Code Encoding","content_includes_title":false,"authors":[{"nameParsed":{"literal":"Cosilico AI","given":"Cosilico","family":"AI"},"name":"Cosilico AI","url":"https://cosilico.ai","id":"contributors-myst-generated-uid-0"}],"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/CosilicoAI/cosilico-engine","source_url":"https://github.com/CosilicoAI/cosilico-engine/blob/main/paper/index.md","edit_url":"https://github.com/CosilicoAI/cosilico-engine/edit/main/paper/index.md","exports":[{"format":"md","filename":"index.md","url":"/index-66180172c6830d0c059ec97f02c7996e.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Reinforcement Learning from Implementation Feedback for Automated Statutory Encoding","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lV0nudnkzs"}],"key":"kEyZHOKEZQ"}],"key":"MvgNUnH7g5"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Cosilico AI | December 2024","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MnPjob8xS8"}],"key":"S3qrBicELZ"},{"type":"thematicBreak","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pZ6vkB0o1O"},{"type":"heading","depth":2,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Abstract","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"g0XR586isY"}],"identifier":"abstract","label":"Abstract","html_id":"abstract","implicit":true,"key":"YfjWyTRcU2"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"We demonstrate that large language models can automatically encode statutory provisions into executable code by using existing implementations as oracles for reinforcement learning. Our agentic loop achieves 95%+ accuracy on tax provisions ranging from simple formulas to complex multi-branch calculations, with costs under $1 per provision. We find evidence of transfer learning—provisions encoded later require fewer iterations—and identify systematic failure modes that inform human oversight requirements.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"RSpjiGJLbB"}],"key":"uhBCO99E6K"},{"type":"thematicBreak","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"p8g5ntWF4A"},{"type":"heading","depth":2,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Quick Links","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"smNkAIeKUx"}],"identifier":"quick-links","label":"Quick Links","html_id":"quick-links","implicit":true,"key":"DRrFY1gqaz"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":17,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"link","url":"/preregistration","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Preregistration","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"TdFzPttq1F"}],"urlSource":"preregistration.md","dataUrl":"/preregistration.json","internal":true,"protocol":"file","key":"SVAhVyRKaz"}],"key":"W7AMQCI1Bl"},{"type":"text","value":": Hypotheses and methods specified before data collection","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"HCqEnRXBXZ"}],"key":"wa0r2LJRU1"}],"key":"SvwRsUjCuo"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"link","url":"/results","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Results","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"U0d240GbbN"}],"urlSource":"results.md","dataUrl":"/results.json","internal":true,"protocol":"file","key":"XtoSgMJjcq"}],"key":"WLws2MK4Wh"},{"type":"text","value":": Empirical findings","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"uyLgPxOXQU"}],"key":"f4bG0E2ul9"}],"key":"CxZfIEgabZ"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"link","url":"https://github.com/CosilicoAI/cosilico-engine","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Code","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"KFCzqErVs8"}],"urlSource":"https://github.com/CosilicoAI/cosilico-engine","error":true,"key":"Rrc4pkZs8l"}],"key":"M629exc0fx"},{"type":"text","value":": Full implementation","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"zSh9a5mPpb"}],"key":"Qf3lhJPONH"}],"key":"oTwdXFZTug"}],"key":"Cl5GCYFBKp"},{"type":"thematicBreak","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"aJpwlgoUxt"},{"type":"heading","depth":2,"position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Citation","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"PdWcoc3BsB"}],"identifier":"citation","label":"Citation","html_id":"citation","implicit":true,"key":"nWzz8bYx8C"},{"type":"code","lang":"bibtex","value":"@article{cosilico2024airules,\n  title={AI-Driven Rules-as-Code Encoding: Reinforcement Learning from Implementation Feedback},\n  author={Cosilico AI},\n  year={2024},\n  url={https://docs.rac.ai/paper}\n}","position":{"start":{"line":25,"column":1},"end":{"line":32,"column":1}},"key":"RiusF3SkPA"}],"key":"OyDqx9I6zd"}],"key":"YV8DaRn2Bd"},"references":{"cite":{"order":[],"data":{}}}}